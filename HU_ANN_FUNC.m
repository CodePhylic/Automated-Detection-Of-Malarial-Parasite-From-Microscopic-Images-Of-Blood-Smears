function [y1] = HU_ANN_FUNC(x1)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Generated by Neural Network Toolbox function genFunction, 26-Jun-2016 15:20:05.
% 
% [y1] = myNeuralNetworkFunction(x1) takes these arguments:
%   x = 7xQ matrix, input #1
% and returns:
%   y = 2xQ matrix, output #1
% where Q is the number of samples.

%#ok<*RPMT0>

  % ===== NEURAL NETWORK CONSTANTS =====
  
  % Input 1
  x1_step1_xoffset = [0.00266991004246266;0;0;0;0;0;0];
  x1_step1_gain = [9.2359521237663;98.5577161925174;22805.2965404331;12175.5114772327;817364456.989398;470748.846263838;168164887.827308];
  x1_step1_ymin = -1;
  
  % Layer 1
  b1 = [1.9462731475126103;-1.051190224147174;-0.15576168347605387;0.87409716581874686;1.4761312288685366];
  IW1_1 = [-2.5322676394489001 0.84872785649250171 -0.732947326068768 0.91469966089308119 -0.31894804900669282 -0.11730966684671844 0.3521125020981693;0.92281985485219875 -0.15659032941838191 -0.49266557678818601 -0.3495274354559107 1.0010267109247732 0.64178073258610535 0.6680958057421863;0.61167441304485215 0.53852918740359312 -0.64341823241737328 1.1066306942078548 0.70785979474673266 0.60255668088513181 -0.42915590729342135;0.34591384726339602 -0.6310182689918955 -0.77947603965221102 -0.90232563437435809 -0.60074009108925108 0.49342642122754815 -0.74066194388914652;1.4390869645087296 0.96805044641399562 1.2279873636359515 -0.16295307079104426 0.21184568346171748 -0.56215192672785896 0.21323916524595443];
  
  % Layer 2
  b2 = [0.10954710834084472;-0.73786716275588005];
  LW2_1 = [2.4662940696766733 -0.013832403376791052 0.41382336478892989 0.015361024309935927 0.095489435078857571;-1.8660346993122441 -0.36800821568138042 -0.40109901525908626 0.394706524333721 1.6048999204036281];
  
  % ===== SIMULATION ========
  
  % Dimensions
  Q = size(x1,2); % samples
  
  % Input 1
  xp1 = mapminmax_apply(x1,x1_step1_gain,x1_step1_xoffset,x1_step1_ymin);
  
  % Layer 1
  a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*xp1);
  
  % Layer 2
  a2 = softmax_apply(repmat(b2,1,Q) + LW2_1*a1);
  
  % Output 1
  y1 = a2;
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings_gain,settings_xoffset,settings_ymin)
  y = bsxfun(@minus,x,settings_xoffset);
  y = bsxfun(@times,y,settings_gain);
  y = bsxfun(@plus,y,settings_ymin);
end

% Competitive Soft Transfer Function
function a = softmax_apply(n)
  nmax = max(n,[],1);
  n = bsxfun(@minus,n,nmax);
  numer = exp(n);
  denom = sum(numer,1); 
  denom(denom == 0) = 1;
  a = bsxfun(@rdivide,numer,denom);
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n)
  a = 2 ./ (1 + exp(-2*n)) - 1;
end
